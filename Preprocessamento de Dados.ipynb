{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Este notebook tem função de limpar os datasets que foram extraídos pela equipe Tera btc-dscbc_jan20 que teve por objetivo analisar alguns impactos do COVID-19 nos teores dos tweets no Brasil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar bibliotecas para isso\n",
    "\n",
    "# bibliotecas gerais\n",
    "import pandas as pd\n",
    "import csv\n",
    "import tqdm\n",
    "\n",
    "# bibliotecas para limpar texto\n",
    "import re\n",
    "import emoji\n",
    "import unicodedata\n",
    "from unicodedata import normalize\n",
    "import nltk\n",
    "from ast import literal_eval\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "#biblioteca sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para retirar alfanuméricos e dígitos\n",
    "\n",
    "def strip_characters(text):\n",
    "    t = re.sub(r'(https?:\\/\\/)(\\s)*(www\\.)?(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*', '', text)\n",
    "    t = re.sub(r'\\(|\\)|:|,|;|\\.|’|”|“|\\?|%|>|<', '', t)\n",
    "    t = re.sub(r'/', ' ', t)\n",
    "    t = t.replace(r\"'\",'')\n",
    "    t = re.sub(r'(@\\w+)+', '', t)\n",
    "    t = t.lower()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função pasra remover caracteres especiais\n",
    "\n",
    "def remover_acentos(txt):\n",
    "    return normalize('NFKD', txt).encode('ASCII', 'ignore').decode('ASCII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para retirar emojis\n",
    "\n",
    "def strip_emoji(text):\n",
    "\n",
    "    new_text = re.sub(emoji.get_emoji_regexp(), r\"\", str(text))\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando stopwords em português utilizando a biblioteca nltk\n",
    "import pt_core_news_sm\n",
    "nlp = pt_core_news_sm.load()\n",
    "pt_stopwords = sorted([token.text for token in nlp.vocab if token.is_stop])\n",
    "list_exclude = ['obrigado', 'bom', 'mal', 'nenhuma', 'maior',\n",
    "             'bem', 'não', 'máximo', 'boa', 'mais',\n",
    "               'bastante', 'certamente', 'certeza', 'contra',\n",
    "                'quarentena', 'coronavírus', 'presidente', 'impeachment', 'demitido', 'demitida']\n",
    "for word in list_exclude:\n",
    "    nlp.vocab[word].is_stop = False\n",
    "list_include = set(['o', 'a', 'tá', 'ta', 'ser', 'pro', 'to', 'tô', 'vc', 'você', 'voce', 'pra',\n",
    "                    'pq', 'é', 'vou', 'que','tão', 'gt', 'de', 'da', 'do', 'em', 'uma', 'lá',\n",
    "                    'já', 'no', 'para', 'na', 'com', 'um', 'minha', 'se', 'isso', 'por', 'vou',\n",
    "                    'os', 'isso', 'como', 'mesmo', 'tenho', 'aqui', 'ele', 'ela', 'quem', 'fazer',\n",
    "                    'eu', 'só', 'ai', 'mais', 'só', 'querer', 'https', 'ter', 'estar', 'ficar',\n",
    "                    'dos', 'das', 'vcs', 'tem', 'as', 'mas','ao'\n",
    "                    'tava', 'nao', 'sao', 'ja', 'so', 'nossa',\n",
    "                    'nosso', 'estao', 'tco', 'me', 'dia', 'te', 'ver', 'sera', 'porra', 'fez', 'ne',\n",
    "                    'kkk','kkkkkk', 'puta', 'kkkkkkkk', 'hj', 'afff', 'gbr', 'meu', 'cara', 'guri', 'cmg',\n",
    "                    'ctg', 'agr', 'pqp', 'vdd', 'eh', 'va', 'obg',\n",
    "                    'corona','virus','coronavirus','covid','covid19','19'\n",
    "                   'nem', 'numa', 'num', 'nuns', 'ces', 'voces', 'oce', 'oces', 'kkkk', 'vao', 'via',\n",
    "                    'hj', 'hoje', 'tudo', 'todo', 'toda',\n",
    "                    'vir', 'bem','ao','sem','ou','vai', 'dizer', 'entao', 'dizer', 'entao',\n",
    "                    'tao', 'tu', 'mim', 'mano', 'oq', 'pos', 'dm', 'dps',\n",
    "                    'coronavirusoutbreak', 'coronavirusPandemic', 'dar', 'vairus',\n",
    "                    'ainda', 'assim']\n",
    "                  )\n",
    "for w in list_include:\n",
    "    nlp.vocab[w].is_stop = True\n",
    "stop_words = sorted([token.text for token in nlp.vocab if token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return list(set([word for word in words \n",
    "                     if len(word) > 1\n",
    "                     and not (word.isnumeric() and len(word) is not 4)\n",
    "                     and (not word.isnumeric() or word.isalpha())] )\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dos tokens\n",
    "\n",
    "df_tokens = pd.read_csv('tokens_unicos_10k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criação de lista de tokens\n",
    "\n",
    "lista_token = []\n",
    "\n",
    "for row in range(0, len(df_tokens)):\n",
    "    lista_token.append(df_tokens.iloc[row,1])\n",
    "    \n",
    "lista_token = set(lista_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para preprocessar palavras\n",
    "\n",
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts1 = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts2 = [bigram_mod[doc] for doc in texts1]\n",
    "    texts3 = [trigram_mod[bigram_mod[doc]] for doc in texts2]\n",
    "    texts4 = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts3]    \n",
    "    return texts4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03/04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (1,6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('corona_tweets_03_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang', 'latitude', 'longitude', 'Unnamed: 0', 'location'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('0304_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02/04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('corona_tweets_02_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1245863582627033088</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>Bolsonaro Ao Vivo https://t.co/8NqTAHyVnA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divinópolis, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1245863582618619904</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>não sei o q tá acontecendo cmg nessa quarenten...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rio de Janeiro, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1245863581830144002</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>jro graças a esse fdp do corona eu vou estar i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caralho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1245863581666570240</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>@veramagalhaes Vc está tranquila pq o Dória já...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1245863579619741697</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>Saudade de aglomerações, corona pf já deu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id           created_at  \\\n",
       "0           0  1245863582627033088  2020-04-02 23:59:59   \n",
       "1           1  1245863582618619904  2020-04-02 23:59:59   \n",
       "2           2  1245863581830144002  2020-04-02 23:59:59   \n",
       "3           3  1245863581666570240  2020-04-02 23:59:59   \n",
       "4           4  1245863579619741697  2020-04-02 23:59:59   \n",
       "\n",
       "                                           full_text country_code lang  \\\n",
       "0          Bolsonaro Ao Vivo https://t.co/8NqTAHyVnA          NaN   pt   \n",
       "1  não sei o q tá acontecendo cmg nessa quarenten...          NaN   pt   \n",
       "2  jro graças a esse fdp do corona eu vou estar i...          NaN   pt   \n",
       "3  @veramagalhaes Vc está tranquila pq o Dória já...          NaN   pt   \n",
       "4          Saudade de aglomerações, corona pf já deu          NaN   pt   \n",
       "\n",
       "   latitude  longitude                location  \n",
       "0       NaN        NaN     Divinópolis, Brasil  \n",
       "1       NaN        NaN  Rio de Janeiro, Brasil  \n",
       "2       NaN        NaN                 caralho  \n",
       "3       NaN        NaN                     NaN  \n",
       "4       NaN        NaN                  Brasil  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang', 'latitude', 'longitude', 'Unnamed: 0', 'location'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245863582627033088</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>Bolsonaro Ao Vivo https://t.co/8NqTAHyVnA</td>\n",
       "      <td>bolsonaro ao vivo</td>\n",
       "      <td>bolsonaro ao vivo</td>\n",
       "      <td>bolsonaro ao vivo</td>\n",
       "      <td>[ao, bolsonaro, vivo]</td>\n",
       "      <td>['vivo', 'bolsonaro']</td>\n",
       "      <td>[vivo, bolsonaro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245863582618619904</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>não sei o q tá acontecendo cmg nessa quarenten...</td>\n",
       "      <td>não sei o q tá acontecendo cmg nessa quarenten...</td>\n",
       "      <td>nao sei o q ta acontecendo cmg nessa quarenten...</td>\n",
       "      <td>nao sei o q ta acontecendo cmg nessa quarenten...</td>\n",
       "      <td>[ja, ta, cmg, sei, acontecendo, nada, choro, q...</td>\n",
       "      <td>['cmg', 'nada', 'ja', 've', 'nao']</td>\n",
       "      <td>[nada, ve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245863581830144002</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>jro graças a esse fdp do corona eu vou estar i...</td>\n",
       "      <td>jro graças a esse fdp do corona eu vou estar i...</td>\n",
       "      <td>jro gracas a esse fdp do corona eu vou estar i...</td>\n",
       "      <td>jro gracas a esse fdp do corona eu vou estar i...</td>\n",
       "      <td>[fdp, ir, mereco, sem, esse, corona, imenso, t...</td>\n",
       "      <td>['fdp', 'imenso', 'corona', 'tempo', 'aldeia',...</td>\n",
       "      <td>[fdp, imenso, tempo, aldeia, ir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245863581666570240</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>@veramagalhaes Vc está tranquila pq o Dória já...</td>\n",
       "      <td>vc está tranquila pq o dória já lhe deu 500mi...</td>\n",
       "      <td>vc esta tranquila pq o doria ja lhe deu 500mi...</td>\n",
       "      <td>vc esta tranquila pq o doria ja lhe deu 500mi...</td>\n",
       "      <td>[politicos, em, 500mil, contrato, ja, de, chan...</td>\n",
       "      <td>['fake', 'jornalismo', 'chantagem', 'doria', '...</td>\n",
       "      <td>[fake, jornalismo, chantagem, doria, pandemia,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245863579619741697</td>\n",
       "      <td>2020-04-02 23:59:59</td>\n",
       "      <td>Saudade de aglomerações, corona pf já deu</td>\n",
       "      <td>saudade de aglomerações corona pf já deu</td>\n",
       "      <td>saudade de aglomeracoes corona pf ja deu</td>\n",
       "      <td>saudade de aglomeracoes corona pf ja deu</td>\n",
       "      <td>[aglomeracoes, pf, saudade, corona, deu, ja, de]</td>\n",
       "      <td>['pf', 'saudade', 'corona', 'ja']</td>\n",
       "      <td>[pf, saudade]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1245863582627033088  2020-04-02 23:59:59   \n",
       "1  1245863582618619904  2020-04-02 23:59:59   \n",
       "2  1245863581830144002  2020-04-02 23:59:59   \n",
       "3  1245863581666570240  2020-04-02 23:59:59   \n",
       "4  1245863579619741697  2020-04-02 23:59:59   \n",
       "\n",
       "                                           full_text  \\\n",
       "0          Bolsonaro Ao Vivo https://t.co/8NqTAHyVnA   \n",
       "1  não sei o q tá acontecendo cmg nessa quarenten...   \n",
       "2  jro graças a esse fdp do corona eu vou estar i...   \n",
       "3  @veramagalhaes Vc está tranquila pq o Dória já...   \n",
       "4          Saudade de aglomerações, corona pf já deu   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "0                                 bolsonaro ao vivo    \n",
       "1  não sei o q tá acontecendo cmg nessa quarenten...   \n",
       "2  jro graças a esse fdp do corona eu vou estar i...   \n",
       "3   vc está tranquila pq o dória já lhe deu 500mi...   \n",
       "4           saudade de aglomerações corona pf já deu   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "0                                 bolsonaro ao vivo    \n",
       "1  nao sei o q ta acontecendo cmg nessa quarenten...   \n",
       "2  jro gracas a esse fdp do corona eu vou estar i...   \n",
       "3   vc esta tranquila pq o doria ja lhe deu 500mi...   \n",
       "4           saudade de aglomeracoes corona pf ja deu   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "0                                 bolsonaro ao vivo    \n",
       "1  nao sei o q ta acontecendo cmg nessa quarenten...   \n",
       "2  jro gracas a esse fdp do corona eu vou estar i...   \n",
       "3   vc esta tranquila pq o doria ja lhe deu 500mi...   \n",
       "4           saudade de aglomeracoes corona pf ja deu   \n",
       "\n",
       "                                               token  \\\n",
       "0                              [ao, bolsonaro, vivo]   \n",
       "1  [ja, ta, cmg, sei, acontecendo, nada, choro, q...   \n",
       "2  [fdp, ir, mereco, sem, esse, corona, imenso, t...   \n",
       "3  [politicos, em, 500mil, contrato, ja, de, chan...   \n",
       "4   [aglomeracoes, pf, saudade, corona, deu, ja, de]   \n",
       "\n",
       "                                              token2  \\\n",
       "0                              ['vivo', 'bolsonaro']   \n",
       "1                 ['cmg', 'nada', 'ja', 've', 'nao']   \n",
       "2  ['fdp', 'imenso', 'corona', 'tempo', 'aldeia',...   \n",
       "3  ['fake', 'jornalismo', 'chantagem', 'doria', '...   \n",
       "4                  ['pf', 'saudade', 'corona', 'ja']   \n",
       "\n",
       "                                              token3  \n",
       "0                                  [vivo, bolsonaro]  \n",
       "1                                         [nada, ve]  \n",
       "2                   [fdp, imenso, tempo, aldeia, ir]  \n",
       "3  [fake, jornalismo, chantagem, doria, pandemia,...  \n",
       "4                                      [pf, saudade]  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('0204_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01/04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('corona_tweets_01_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245501195344646145</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>em tempos de pandemia.. o mundo um caos.. e so...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recife, Pernambuco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245501195227213825</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>@LuisH_fad @DanPerdigaoo @DiiegoDigs  foi muit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245501193910194177</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>Eu só queria que o Cine Bangue colocasse Yoñlu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cabedelo, Paraíba, Brasil.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245501193431982081</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>@CarlosBolsonaro Obrigado, família Bolsonaro p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Campo Alegre, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245501193230725121</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>ler quarto de despejo nessa quarentena tá send...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1245501195344646145  2020-04-01 23:59:59   \n",
       "1  1245501195227213825  2020-04-01 23:59:59   \n",
       "2  1245501193910194177  2020-04-01 23:59:59   \n",
       "3  1245501193431982081  2020-04-01 23:59:59   \n",
       "4  1245501193230725121  2020-04-01 23:59:59   \n",
       "\n",
       "                                           full_text country_code lang  \\\n",
       "0  em tempos de pandemia.. o mundo um caos.. e so...          NaN   pt   \n",
       "1  @LuisH_fad @DanPerdigaoo @DiiegoDigs  foi muit...          NaN   pt   \n",
       "2  Eu só queria que o Cine Bangue colocasse Yoñlu...          NaN   pt   \n",
       "3  @CarlosBolsonaro Obrigado, família Bolsonaro p...          NaN   pt   \n",
       "4  ler quarto de despejo nessa quarentena tá send...          NaN   pt   \n",
       "\n",
       "   latitude  longitude                    location  \n",
       "0       NaN        NaN          Recife, Pernambuco  \n",
       "1       NaN        NaN                         NaN  \n",
       "2       NaN        NaN  Cabedelo, Paraíba, Brasil.  \n",
       "3       NaN        NaN        Campo Alegre, Brasil  \n",
       "4       NaN        NaN                      Brasil  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang', 'latitude', 'longitude', 'location'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245501195344646145</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>em tempos de pandemia.. o mundo um caos.. e so...</td>\n",
       "      <td>em tempos de pandemia o mundo um caos e so pen...</td>\n",
       "      <td>em tempos de pandemia o mundo um caos e so pen...</td>\n",
       "      <td>em tempos de pandemia o mundo um caos e so pen...</td>\n",
       "      <td>[ta, em, deve, tempos, povo, fotos, por, de, l...</td>\n",
       "      <td>['lavar', 'pandemia', 'ter', 'povo', 'so', 'ma...</td>\n",
       "      <td>[lavar, pandemia, povo, mao, mundo, luana, pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245501195227213825</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>@LuisH_fad @DanPerdigaoo @DiiegoDigs  foi muit...</td>\n",
       "      <td>foi muito bom conhecer voces mas dessa qua...</td>\n",
       "      <td>foi muito bom conhecer voces mas dessa qua...</td>\n",
       "      <td>foi muito bom conhecer voces mas dessa qua...</td>\n",
       "      <td>[mas, bom, voces, muito, conhecer, passo, eu, ...</td>\n",
       "      <td>['bom', 'voces', 'muito', 'conhecer', 'passo',...</td>\n",
       "      <td>[bom, muito, conhecer, passo, adeus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245501193910194177</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>Eu só queria que o Cine Bangue colocasse Yoñlu...</td>\n",
       "      <td>eu só queria que o cine bangue colocasse yoñlu...</td>\n",
       "      <td>eu so queria que o cine bangue colocasse yonlu...</td>\n",
       "      <td>eu so queria que o cine bangue colocasse yonlu...</td>\n",
       "      <td>[cine, em, dessa, de, eu, queria, muito, pra, ...</td>\n",
       "      <td>['filme', 'pandemia', 'muito', 'me', 'acabar',...</td>\n",
       "      <td>[filme, pandemia, muito, acabar, chorar, depoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245501193431982081</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>@CarlosBolsonaro Obrigado, família Bolsonaro p...</td>\n",
       "      <td>obrigado família bolsonaro por implantar o so...</td>\n",
       "      <td>obrigado familia bolsonaro por implantar o so...</td>\n",
       "      <td>obrigado familia bolsonaro por implantar o so...</td>\n",
       "      <td>[hein, socialismo, brasil, implantar, que, bol...</td>\n",
       "      <td>['hein', 'socialismo', 'brasil', 'implantar', ...</td>\n",
       "      <td>[hein, socialismo, brasil, implantar, bolsonar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245501193230725121</td>\n",
       "      <td>2020-04-01 23:59:59</td>\n",
       "      <td>ler quarto de despejo nessa quarentena tá send...</td>\n",
       "      <td>ler quarto de despejo nessa quarentena tá send...</td>\n",
       "      <td>ler quarto de despejo nessa quarentena ta send...</td>\n",
       "      <td>ler quarto de despejo nessa quarentena ta send...</td>\n",
       "      <td>[sendo, na, minha, um, ta, ler, pra, quarto, a...</td>\n",
       "      <td>['ler', 'quarto', 'acordar']</td>\n",
       "      <td>[ler, quarto, acordar]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1245501195344646145  2020-04-01 23:59:59   \n",
       "1  1245501195227213825  2020-04-01 23:59:59   \n",
       "2  1245501193910194177  2020-04-01 23:59:59   \n",
       "3  1245501193431982081  2020-04-01 23:59:59   \n",
       "4  1245501193230725121  2020-04-01 23:59:59   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  em tempos de pandemia.. o mundo um caos.. e so...   \n",
       "1  @LuisH_fad @DanPerdigaoo @DiiegoDigs  foi muit...   \n",
       "2  Eu só queria que o Cine Bangue colocasse Yoñlu...   \n",
       "3  @CarlosBolsonaro Obrigado, família Bolsonaro p...   \n",
       "4  ler quarto de despejo nessa quarentena tá send...   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "0  em tempos de pandemia o mundo um caos e so pen...   \n",
       "1      foi muito bom conhecer voces mas dessa qua...   \n",
       "2  eu só queria que o cine bangue colocasse yoñlu...   \n",
       "3   obrigado família bolsonaro por implantar o so...   \n",
       "4  ler quarto de despejo nessa quarentena tá send...   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "0  em tempos de pandemia o mundo um caos e so pen...   \n",
       "1      foi muito bom conhecer voces mas dessa qua...   \n",
       "2  eu so queria que o cine bangue colocasse yonlu...   \n",
       "3   obrigado familia bolsonaro por implantar o so...   \n",
       "4  ler quarto de despejo nessa quarentena ta send...   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "0  em tempos de pandemia o mundo um caos e so pen...   \n",
       "1      foi muito bom conhecer voces mas dessa qua...   \n",
       "2  eu so queria que o cine bangue colocasse yonlu...   \n",
       "3   obrigado familia bolsonaro por implantar o so...   \n",
       "4  ler quarto de despejo nessa quarentena ta send...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [ta, em, deve, tempos, povo, fotos, por, de, l...   \n",
       "1  [mas, bom, voces, muito, conhecer, passo, eu, ...   \n",
       "2  [cine, em, dessa, de, eu, queria, muito, pra, ...   \n",
       "3  [hein, socialismo, brasil, implantar, que, bol...   \n",
       "4  [sendo, na, minha, um, ta, ler, pra, quarto, a...   \n",
       "\n",
       "                                              token2  \\\n",
       "0  ['lavar', 'pandemia', 'ter', 'povo', 'so', 'ma...   \n",
       "1  ['bom', 'voces', 'muito', 'conhecer', 'passo',...   \n",
       "2  ['filme', 'pandemia', 'muito', 'me', 'acabar',...   \n",
       "3  ['hein', 'socialismo', 'brasil', 'implantar', ...   \n",
       "4                       ['ler', 'quarto', 'acordar']   \n",
       "\n",
       "                                              token3  \n",
       "0  [lavar, pandemia, povo, mao, mundo, luana, pos...  \n",
       "1               [bom, muito, conhecer, passo, adeus]  \n",
       "2  [filme, pandemia, muito, acabar, chorar, depoi...  \n",
       "3  [hein, socialismo, brasil, implantar, bolsonar...  \n",
       "4                             [ler, quarto, acordar]  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('0104_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('corona_tweets_31_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245138807332253696</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>@LeilaneNeubarth Gostei da fala do presidente ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belém, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245138807151878145</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>Início da quarentena // Metade da quarentena h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245138806984134656</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>eu olho pro bolsonaro e vejo o reflexo do hitl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>derry 🎈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245138806891843585</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>@zitosilva Eu sinto um misto: quero que saia /...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recife, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245138806543732740</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>#bbb20 Bolsonaro trocou a boca pelo cú em rede...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1245138807332253696  2020-03-31 23:59:59   \n",
       "1  1245138807151878145  2020-03-31 23:59:59   \n",
       "2  1245138806984134656  2020-03-31 23:59:59   \n",
       "3  1245138806891843585  2020-03-31 23:59:59   \n",
       "4  1245138806543732740  2020-03-31 23:59:59   \n",
       "\n",
       "                                           full_text country_code lang  \\\n",
       "0  @LeilaneNeubarth Gostei da fala do presidente ...          NaN   pt   \n",
       "1  Início da quarentena // Metade da quarentena h...          NaN   pt   \n",
       "2  eu olho pro bolsonaro e vejo o reflexo do hitl...          NaN   pt   \n",
       "3  @zitosilva Eu sinto um misto: quero que saia /...          NaN   pt   \n",
       "4  #bbb20 Bolsonaro trocou a boca pelo cú em rede...          NaN   pt   \n",
       "\n",
       "   latitude  longitude        location  \n",
       "0       NaN        NaN   Belém, Brasil  \n",
       "1       NaN        NaN             NaN  \n",
       "2       NaN        NaN         derry 🎈  \n",
       "3       NaN        NaN  Recife, Brasil  \n",
       "4       NaN        NaN             NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang', 'latitude', 'longitude', 'location'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245138807332253696</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>@LeilaneNeubarth Gostei da fala do presidente ...</td>\n",
       "      <td>gostei da fala do presidente  \\r\\nagradeceu a...</td>\n",
       "      <td>gostei da fala do presidente  \\r\\nagradeceu a...</td>\n",
       "      <td>gostei da fala do presidente  \\r\\nagradeceu a...</td>\n",
       "      <td>[imprensa, gostei, agradeceu, menos, da, do, p...</td>\n",
       "      <td>['menos', 'presidente']</td>\n",
       "      <td>[menos, presidente]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245138807151878145</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>Início da quarentena // Metade da quarentena h...</td>\n",
       "      <td>início da quarentena    metade da quarentena</td>\n",
       "      <td>inicio da quarentena    metade da quarentena</td>\n",
       "      <td>inicio da quarentena    metade da quarentena</td>\n",
       "      <td>[da, inicio, metade, quarentena]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245138806984134656</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>eu olho pro bolsonaro e vejo o reflexo do hitl...</td>\n",
       "      <td>eu olho pro bolsonaro e vejo o reflexo do hitl...</td>\n",
       "      <td>eu olho pro bolsonaro e vejo o reflexo do hitl...</td>\n",
       "      <td>eu olho pro bolsonaro e vejo o reflexo do hitl...</td>\n",
       "      <td>[medo, quero, vejo, odio, hitler, olho, reflex...</td>\n",
       "      <td>['medo', 'odio', 'hitler', 'olho', 'reflexo', ...</td>\n",
       "      <td>[medo, odio, hitler, olho, reflexo, chorar, bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245138806891843585</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>@zitosilva Eu sinto um misto: quero que saia /...</td>\n",
       "      <td>eu sinto um misto quero que saia   tenho medo...</td>\n",
       "      <td>eu sinto um misto quero que saia   tenho medo...</td>\n",
       "      <td>eu sinto um misto quero que saia   tenho medo...</td>\n",
       "      <td>[misto, medo, quero, assume, bem, tenho, de, e...</td>\n",
       "      <td>['misto', 'medo', 'diferente', 'bem', 'mourao'...</td>\n",
       "      <td>[misto, medo, diferente, mourao, bolsonaro, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245138806543732740</td>\n",
       "      <td>2020-03-31 23:59:59</td>\n",
       "      <td>#bbb20 Bolsonaro trocou a boca pelo cú em rede...</td>\n",
       "      <td>#bbb20 bolsonaro trocou a boca pelo cú em rede...</td>\n",
       "      <td>#bbb20 bolsonaro trocou a boca pelo cu em rede...</td>\n",
       "      <td>#bbb20 bolsonaro trocou a boca pelo cu em rede...</td>\n",
       "      <td>[trocou, rede, nacional, em, bbb20, pelo, bols...</td>\n",
       "      <td>['rede', 'nacional', 'bolsonaro', 'boca', 'cu']</td>\n",
       "      <td>[rede, nacional, bolsonaro, boca, cu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1245138807332253696  2020-03-31 23:59:59   \n",
       "1  1245138807151878145  2020-03-31 23:59:59   \n",
       "2  1245138806984134656  2020-03-31 23:59:59   \n",
       "3  1245138806891843585  2020-03-31 23:59:59   \n",
       "4  1245138806543732740  2020-03-31 23:59:59   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  @LeilaneNeubarth Gostei da fala do presidente ...   \n",
       "1  Início da quarentena // Metade da quarentena h...   \n",
       "2  eu olho pro bolsonaro e vejo o reflexo do hitl...   \n",
       "3  @zitosilva Eu sinto um misto: quero que saia /...   \n",
       "4  #bbb20 Bolsonaro trocou a boca pelo cú em rede...   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "0   gostei da fala do presidente  \\r\\nagradeceu a...   \n",
       "1      início da quarentena    metade da quarentena    \n",
       "2  eu olho pro bolsonaro e vejo o reflexo do hitl...   \n",
       "3   eu sinto um misto quero que saia   tenho medo...   \n",
       "4  #bbb20 bolsonaro trocou a boca pelo cú em rede...   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "0   gostei da fala do presidente  \\r\\nagradeceu a...   \n",
       "1      inicio da quarentena    metade da quarentena    \n",
       "2  eu olho pro bolsonaro e vejo o reflexo do hitl...   \n",
       "3   eu sinto um misto quero que saia   tenho medo...   \n",
       "4  #bbb20 bolsonaro trocou a boca pelo cu em rede...   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "0   gostei da fala do presidente  \\r\\nagradeceu a...   \n",
       "1      inicio da quarentena    metade da quarentena    \n",
       "2  eu olho pro bolsonaro e vejo o reflexo do hitl...   \n",
       "3   eu sinto um misto quero que saia   tenho medo...   \n",
       "4  #bbb20 bolsonaro trocou a boca pelo cu em rede...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [imprensa, gostei, agradeceu, menos, da, do, p...   \n",
       "1                   [da, inicio, metade, quarentena]   \n",
       "2  [medo, quero, vejo, odio, hitler, olho, reflex...   \n",
       "3  [misto, medo, quero, assume, bem, tenho, de, e...   \n",
       "4  [trocou, rede, nacional, em, bbb20, pelo, bols...   \n",
       "\n",
       "                                              token2  \\\n",
       "0                            ['menos', 'presidente']   \n",
       "1                                                 []   \n",
       "2  ['medo', 'odio', 'hitler', 'olho', 'reflexo', ...   \n",
       "3  ['misto', 'medo', 'diferente', 'bem', 'mourao'...   \n",
       "4    ['rede', 'nacional', 'bolsonaro', 'boca', 'cu']   \n",
       "\n",
       "                                              token3  \n",
       "0                                [menos, presidente]  \n",
       "1                                                 []  \n",
       "2  [medo, odio, hitler, olho, reflexo, chorar, bo...  \n",
       "3  [misto, medo, diferente, mourao, bolsonaro, in...  \n",
       "4              [rede, nacional, bolsonaro, boca, cu]  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('3103_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 29/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('corona_tweets_29.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244414031575887880</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Desespero nos EUA. @realDonaldTrump chegou a o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Paulo, Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244414030900596736</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@HaddadDebochado ABESTADOHHH?????? O PRESIDENT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Macaé, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244414030342750208</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Secretário da Saúde do Ceará, Dr. Cabeto, test...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contagem, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244414030070140928</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@RASPUTINDECARV1 Nandão curtindo que o bolsona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244414029998759938</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@delbura Queria, o tema vai ser corona vírus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1244414031575887880  2020-03-29 23:59:59   \n",
       "1  1244414030900596736  2020-03-29 23:59:59   \n",
       "2  1244414030342750208  2020-03-29 23:59:59   \n",
       "3  1244414030070140928  2020-03-29 23:59:59   \n",
       "4  1244414029998759938  2020-03-29 23:59:59   \n",
       "\n",
       "                                           full_text country_code lang  \\\n",
       "0  Desespero nos EUA. @realDonaldTrump chegou a o...          NaN   pt   \n",
       "1  @HaddadDebochado ABESTADOHHH?????? O PRESIDENT...          NaN   pt   \n",
       "2  Secretário da Saúde do Ceará, Dr. Cabeto, test...          NaN   pt   \n",
       "3  @RASPUTINDECARV1 Nandão curtindo que o bolsona...          NaN   pt   \n",
       "4       @delbura Queria, o tema vai ser corona vírus          NaN   pt   \n",
       "\n",
       "   latitude  longitude           location  \n",
       "0       NaN        NaN  São Paulo, Brazil  \n",
       "1       NaN        NaN      Macaé, Brasil  \n",
       "2       NaN        NaN   Contagem, Brasil  \n",
       "3       NaN        NaN                NaN  \n",
       "4       NaN        NaN                NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang', 'latitude', 'longitude', 'location'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244414031575887880</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Desespero nos EUA. @realDonaldTrump chegou a o...</td>\n",
       "      <td>desespero nos eua  chegou a obrigar por lei qu...</td>\n",
       "      <td>desespero nos eua  chegou a obrigar por lei qu...</td>\n",
       "      <td>desespero nos eua  chegou a obrigar por lei qu...</td>\n",
       "      <td>[serao, lei, panico, amigos, por, de, respirad...</td>\n",
       "      <td>['serao', 'lei', 'panico', 'eua', 'obrigar', '...</td>\n",
       "      <td>[serao, lei, panico, eua, obrigar, fabricar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244414030900596736</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@HaddadDebochado ABESTADOHHH?????? O PRESIDENT...</td>\n",
       "      <td>abestadohhh o presidente realmente estava doente</td>\n",
       "      <td>abestadohhh o presidente realmente estava doente</td>\n",
       "      <td>abestadohhh o presidente realmente estava doente</td>\n",
       "      <td>[abestadohhh, realmente, presidente, doente, e...</td>\n",
       "      <td>['realmente', 'doente', 'presidente']</td>\n",
       "      <td>[realmente, doente, presidente]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244414030342750208</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Secretário da Saúde do Ceará, Dr. Cabeto, test...</td>\n",
       "      <td>secretário da saúde do ceará dr cabeto testa p...</td>\n",
       "      <td>secretario da saude do ceara dr cabeto testa p...</td>\n",
       "      <td>secretario da saude do ceara dr cabeto testa p...</td>\n",
       "      <td>[testa, saude, novo, coronavirus, cabeto, posi...</td>\n",
       "      <td>['saude', 'novo', 'coronavirus', 'cabeto', 'po...</td>\n",
       "      <td>[saude, novo, cabeto, positivo, dr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244414030070140928</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@RASPUTINDECARV1 Nandão curtindo que o bolsona...</td>\n",
       "      <td>nandão curtindo que o bolsonarismo está viran...</td>\n",
       "      <td>nandao curtindo que o bolsonarismo esta viran...</td>\n",
       "      <td>nandao curtindo que o bolsonarismo esta viran...</td>\n",
       "      <td>[minhas, isso, nandotenho, curtindo, falou, na...</td>\n",
       "      <td>['bolsonarismo', 'me', 'besteira']</td>\n",
       "      <td>[bolsonarismo, besteira]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244414029998759938</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@delbura Queria, o tema vai ser corona vírus</td>\n",
       "      <td>queria o tema vai ser corona vírus</td>\n",
       "      <td>queria o tema vai ser corona virus</td>\n",
       "      <td>queria o tema vai ser corona virus</td>\n",
       "      <td>[queria, tema, vai, corona, virus, ser]</td>\n",
       "      <td>['corona', 'virus']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1244414031575887880  2020-03-29 23:59:59   \n",
       "1  1244414030900596736  2020-03-29 23:59:59   \n",
       "2  1244414030342750208  2020-03-29 23:59:59   \n",
       "3  1244414030070140928  2020-03-29 23:59:59   \n",
       "4  1244414029998759938  2020-03-29 23:59:59   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Desespero nos EUA. @realDonaldTrump chegou a o...   \n",
       "1  @HaddadDebochado ABESTADOHHH?????? O PRESIDENT...   \n",
       "2  Secretário da Saúde do Ceará, Dr. Cabeto, test...   \n",
       "3  @RASPUTINDECARV1 Nandão curtindo que o bolsona...   \n",
       "4       @delbura Queria, o tema vai ser corona vírus   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "0  desespero nos eua  chegou a obrigar por lei qu...   \n",
       "1   abestadohhh o presidente realmente estava doente   \n",
       "2  secretário da saúde do ceará dr cabeto testa p...   \n",
       "3   nandão curtindo que o bolsonarismo está viran...   \n",
       "4                 queria o tema vai ser corona vírus   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "0  desespero nos eua  chegou a obrigar por lei qu...   \n",
       "1   abestadohhh o presidente realmente estava doente   \n",
       "2  secretario da saude do ceara dr cabeto testa p...   \n",
       "3   nandao curtindo que o bolsonarismo esta viran...   \n",
       "4                 queria o tema vai ser corona virus   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "0  desespero nos eua  chegou a obrigar por lei qu...   \n",
       "1   abestadohhh o presidente realmente estava doente   \n",
       "2  secretario da saude do ceara dr cabeto testa p...   \n",
       "3   nandao curtindo que o bolsonarismo esta viran...   \n",
       "4                 queria o tema vai ser corona virus   \n",
       "\n",
       "                                               token  \\\n",
       "0  [serao, lei, panico, amigos, por, de, respirad...   \n",
       "1  [abestadohhh, realmente, presidente, doente, e...   \n",
       "2  [testa, saude, novo, coronavirus, cabeto, posi...   \n",
       "3  [minhas, isso, nandotenho, curtindo, falou, na...   \n",
       "4            [queria, tema, vai, corona, virus, ser]   \n",
       "\n",
       "                                              token2  \\\n",
       "0  ['serao', 'lei', 'panico', 'eua', 'obrigar', '...   \n",
       "1              ['realmente', 'doente', 'presidente']   \n",
       "2  ['saude', 'novo', 'coronavirus', 'cabeto', 'po...   \n",
       "3                 ['bolsonarismo', 'me', 'besteira']   \n",
       "4                                ['corona', 'virus']   \n",
       "\n",
       "                                         token3  \n",
       "0  [serao, lei, panico, eua, obrigar, fabricar]  \n",
       "1               [realmente, doente, presidente]  \n",
       "2           [saude, novo, cabeto, positivo, dr]  \n",
       "3                      [bolsonarismo, besteira]  \n",
       "4                                            []  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('2903_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 28/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0,5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('corona_tweets_28csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>created_at</td>\n",
       "      <td>full_text</td>\n",
       "      <td>country_code</td>\n",
       "      <td>lang</td>\n",
       "      <td>latitude</td>\n",
       "      <td>longitude</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244414031575887880</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Desespero nos EUA. @realDonaldTrump chegou a o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Paulo, Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244414030900596736</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@HaddadDebochado ABESTADOHHH?????? O PRESIDENT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Macaé, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244414030342750208</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Secretário da Saúde do Ceará, Dr. Cabeto, test...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contagem, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244414030070140928</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@RASPUTINDECARV1 Nandão curtindo que o bolsona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0                   id           created_at   \n",
       "1  1244414031575887880  2020-03-29 23:59:59   \n",
       "2  1244414030900596736  2020-03-29 23:59:59   \n",
       "3  1244414030342750208  2020-03-29 23:59:59   \n",
       "4  1244414030070140928  2020-03-29 23:59:59   \n",
       "\n",
       "                                           full_text  country_code  lang  \\\n",
       "0                                          full_text  country_code  lang   \n",
       "1  Desespero nos EUA. @realDonaldTrump chegou a o...           NaN    pt   \n",
       "2  @HaddadDebochado ABESTADOHHH?????? O PRESIDENT...           NaN    pt   \n",
       "3  Secretário da Saúde do Ceará, Dr. Cabeto, test...           NaN    pt   \n",
       "4  @RASPUTINDECARV1 Nandão curtindo que o bolsona...           NaN    pt   \n",
       "\n",
       "   latitude  longitude           location  \n",
       "0  latitude  longitude           location  \n",
       "1       NaN        NaN  São Paulo, Brazil  \n",
       "2       NaN        NaN      Macaé, Brasil  \n",
       "3       NaN        NaN   Contagem, Brasil  \n",
       "4       NaN        NaN                NaN  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244414031575887880</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Desespero nos EUA. @realDonaldTrump chegou a o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Paulo, Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244414030900596736</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@HaddadDebochado ABESTADOHHH?????? O PRESIDENT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Macaé, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244414030342750208</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Secretário da Saúde do Ceará, Dr. Cabeto, test...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contagem, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244414030070140928</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@RASPUTINDECARV1 Nandão curtindo que o bolsona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1244414029998759938</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@delbura Queria, o tema vai ser corona vírus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "1  1244414031575887880  2020-03-29 23:59:59   \n",
       "2  1244414030900596736  2020-03-29 23:59:59   \n",
       "3  1244414030342750208  2020-03-29 23:59:59   \n",
       "4  1244414030070140928  2020-03-29 23:59:59   \n",
       "5  1244414029998759938  2020-03-29 23:59:59   \n",
       "\n",
       "                                           full_text country_code lang  \\\n",
       "1  Desespero nos EUA. @realDonaldTrump chegou a o...          NaN   pt   \n",
       "2  @HaddadDebochado ABESTADOHHH?????? O PRESIDENT...          NaN   pt   \n",
       "3  Secretário da Saúde do Ceará, Dr. Cabeto, test...          NaN   pt   \n",
       "4  @RASPUTINDECARV1 Nandão curtindo que o bolsona...          NaN   pt   \n",
       "5       @delbura Queria, o tema vai ser corona vírus          NaN   pt   \n",
       "\n",
       "  latitude longitude           location  \n",
       "1      NaN       NaN  São Paulo, Brazil  \n",
       "2      NaN       NaN      Macaé, Brasil  \n",
       "3      NaN       NaN   Contagem, Brasil  \n",
       "4      NaN       NaN                NaN  \n",
       "5      NaN       NaN                NaN  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang', 'latitude', 'longitude', 'location'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244414031575887880</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Desespero nos EUA. @realDonaldTrump chegou a o...</td>\n",
       "      <td>desespero nos eua  chegou a obrigar por lei qu...</td>\n",
       "      <td>desespero nos eua  chegou a obrigar por lei qu...</td>\n",
       "      <td>desespero nos eua  chegou a obrigar por lei qu...</td>\n",
       "      <td>[serao, lei, panico, amigos, por, de, respirad...</td>\n",
       "      <td>['serao', 'lei', 'panico', 'eua', 'obrigar', '...</td>\n",
       "      <td>[serao, lei, panico, eua, obrigar, fabricar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244414030900596736</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@HaddadDebochado ABESTADOHHH?????? O PRESIDENT...</td>\n",
       "      <td>abestadohhh o presidente realmente estava doente</td>\n",
       "      <td>abestadohhh o presidente realmente estava doente</td>\n",
       "      <td>abestadohhh o presidente realmente estava doente</td>\n",
       "      <td>[abestadohhh, realmente, presidente, doente, e...</td>\n",
       "      <td>['realmente', 'doente', 'presidente']</td>\n",
       "      <td>[realmente, doente, presidente]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244414030342750208</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>Secretário da Saúde do Ceará, Dr. Cabeto, test...</td>\n",
       "      <td>secretário da saúde do ceará dr cabeto testa p...</td>\n",
       "      <td>secretario da saude do ceara dr cabeto testa p...</td>\n",
       "      <td>secretario da saude do ceara dr cabeto testa p...</td>\n",
       "      <td>[testa, saude, novo, coronavirus, cabeto, posi...</td>\n",
       "      <td>['saude', 'novo', 'coronavirus', 'cabeto', 'po...</td>\n",
       "      <td>[saude, novo, cabeto, positivo, dr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244414030070140928</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@RASPUTINDECARV1 Nandão curtindo que o bolsona...</td>\n",
       "      <td>nandão curtindo que o bolsonarismo está viran...</td>\n",
       "      <td>nandao curtindo que o bolsonarismo esta viran...</td>\n",
       "      <td>nandao curtindo que o bolsonarismo esta viran...</td>\n",
       "      <td>[minhas, isso, nandotenho, curtindo, falou, na...</td>\n",
       "      <td>['bolsonarismo', 'me', 'besteira']</td>\n",
       "      <td>[bolsonarismo, besteira]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1244414029998759938</td>\n",
       "      <td>2020-03-29 23:59:59</td>\n",
       "      <td>@delbura Queria, o tema vai ser corona vírus</td>\n",
       "      <td>queria o tema vai ser corona vírus</td>\n",
       "      <td>queria o tema vai ser corona virus</td>\n",
       "      <td>queria o tema vai ser corona virus</td>\n",
       "      <td>[queria, tema, vai, corona, virus, ser]</td>\n",
       "      <td>['corona', 'virus']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "1  1244414031575887880  2020-03-29 23:59:59   \n",
       "2  1244414030900596736  2020-03-29 23:59:59   \n",
       "3  1244414030342750208  2020-03-29 23:59:59   \n",
       "4  1244414030070140928  2020-03-29 23:59:59   \n",
       "5  1244414029998759938  2020-03-29 23:59:59   \n",
       "\n",
       "                                           full_text  \\\n",
       "1  Desespero nos EUA. @realDonaldTrump chegou a o...   \n",
       "2  @HaddadDebochado ABESTADOHHH?????? O PRESIDENT...   \n",
       "3  Secretário da Saúde do Ceará, Dr. Cabeto, test...   \n",
       "4  @RASPUTINDECARV1 Nandão curtindo que o bolsona...   \n",
       "5       @delbura Queria, o tema vai ser corona vírus   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "1  desespero nos eua  chegou a obrigar por lei qu...   \n",
       "2   abestadohhh o presidente realmente estava doente   \n",
       "3  secretário da saúde do ceará dr cabeto testa p...   \n",
       "4   nandão curtindo que o bolsonarismo está viran...   \n",
       "5                 queria o tema vai ser corona vírus   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "1  desespero nos eua  chegou a obrigar por lei qu...   \n",
       "2   abestadohhh o presidente realmente estava doente   \n",
       "3  secretario da saude do ceara dr cabeto testa p...   \n",
       "4   nandao curtindo que o bolsonarismo esta viran...   \n",
       "5                 queria o tema vai ser corona virus   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "1  desespero nos eua  chegou a obrigar por lei qu...   \n",
       "2   abestadohhh o presidente realmente estava doente   \n",
       "3  secretario da saude do ceara dr cabeto testa p...   \n",
       "4   nandao curtindo que o bolsonarismo esta viran...   \n",
       "5                 queria o tema vai ser corona virus   \n",
       "\n",
       "                                               token  \\\n",
       "1  [serao, lei, panico, amigos, por, de, respirad...   \n",
       "2  [abestadohhh, realmente, presidente, doente, e...   \n",
       "3  [testa, saude, novo, coronavirus, cabeto, posi...   \n",
       "4  [minhas, isso, nandotenho, curtindo, falou, na...   \n",
       "5            [queria, tema, vai, corona, virus, ser]   \n",
       "\n",
       "                                              token2  \\\n",
       "1  ['serao', 'lei', 'panico', 'eua', 'obrigar', '...   \n",
       "2              ['realmente', 'doente', 'presidente']   \n",
       "3  ['saude', 'novo', 'coronavirus', 'cabeto', 'po...   \n",
       "4                 ['bolsonarismo', 'me', 'besteira']   \n",
       "5                                ['corona', 'virus']   \n",
       "\n",
       "                                         token3  \n",
       "1  [serao, lei, panico, eua, obrigar, fabricar]  \n",
       "2               [realmente, doente, presidente]  \n",
       "3           [saude, novo, cabeto, positivo, dr]  \n",
       "4                      [bolsonarismo, besteira]  \n",
       "5                                            []  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('2803_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0,5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('corona_tweets_27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>created_at</td>\n",
       "      <td>full_text</td>\n",
       "      <td>country_code</td>\n",
       "      <td>lang</td>\n",
       "      <td>latitude</td>\n",
       "      <td>longitude</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1243689256205406208</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>É bom mostrar na tv mesmo o rosto e depoimento...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1243689256163463169</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>@Eli3nai_ poste, azar é quarentena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Santa Catarina, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1243689255534239744</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>@ZemaVieira eu indo pro tecno depois da quaren...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1243689255471325185</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>quarentena por favor acabe vc está me matando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sorocaos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0                   id           created_at   \n",
       "1  1243689256205406208  2020-03-27 23:59:59   \n",
       "2  1243689256163463169  2020-03-27 23:59:59   \n",
       "3  1243689255534239744  2020-03-27 23:59:59   \n",
       "4  1243689255471325185  2020-03-27 23:59:59   \n",
       "\n",
       "                                           full_text  country_code  lang  \\\n",
       "0                                          full_text  country_code  lang   \n",
       "1  É bom mostrar na tv mesmo o rosto e depoimento...           NaN    pt   \n",
       "2                 @Eli3nai_ poste, azar é quarentena           NaN    pt   \n",
       "3  @ZemaVieira eu indo pro tecno depois da quaren...           NaN    pt   \n",
       "4      quarentena por favor acabe vc está me matando           NaN    pt   \n",
       "\n",
       "   latitude  longitude                location  \n",
       "0  latitude  longitude                location  \n",
       "1       NaN        NaN                      AM  \n",
       "2       NaN        NaN  Santa Catarina, Brasil  \n",
       "3       NaN        NaN                     NaN  \n",
       "4       NaN        NaN                sorocaos  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1243689256205406208</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>É bom mostrar na tv mesmo o rosto e depoimento...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1243689256163463169</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>@Eli3nai_ poste, azar é quarentena</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Santa Catarina, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1243689255534239744</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>@ZemaVieira eu indo pro tecno depois da quaren...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1243689255471325185</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>quarentena por favor acabe vc está me matando</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sorocaos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1243689254401826819</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>@carlosmaxhado a mãe de todo mundo tá fumando ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Campinas, Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "1  1243689256205406208  2020-03-27 23:59:59   \n",
       "2  1243689256163463169  2020-03-27 23:59:59   \n",
       "3  1243689255534239744  2020-03-27 23:59:59   \n",
       "4  1243689255471325185  2020-03-27 23:59:59   \n",
       "5  1243689254401826819  2020-03-27 23:59:59   \n",
       "\n",
       "                                           full_text country_code lang  \\\n",
       "1  É bom mostrar na tv mesmo o rosto e depoimento...          NaN   pt   \n",
       "2                 @Eli3nai_ poste, azar é quarentena          NaN   pt   \n",
       "3  @ZemaVieira eu indo pro tecno depois da quaren...          NaN   pt   \n",
       "4      quarentena por favor acabe vc está me matando          NaN   pt   \n",
       "5  @carlosmaxhado a mãe de todo mundo tá fumando ...          NaN   pt   \n",
       "\n",
       "  latitude longitude                location  \n",
       "1      NaN       NaN                      AM  \n",
       "2      NaN       NaN  Santa Catarina, Brasil  \n",
       "3      NaN       NaN                     NaN  \n",
       "4      NaN       NaN                sorocaos  \n",
       "5      NaN       NaN        Campinas, Brasil  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang', 'latitude', 'longitude', 'location'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1243689256205406208</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>É bom mostrar na tv mesmo o rosto e depoimento...</td>\n",
       "      <td>é bom mostrar na tv mesmo o rosto e depoimento...</td>\n",
       "      <td>e bom mostrar na tv mesmo o rosto e depoimento...</td>\n",
       "      <td>e bom mostrar na tv mesmo o rosto e depoimento...</td>\n",
       "      <td>[imundo, depoimento, mesmo, de, chamar, na, do...</td>\n",
       "      <td>['chamar', 'bom', 'imundo', 'depoimento', 'tv'...</td>\n",
       "      <td>[chamar, bom, imundo, depoimento, tv, mostrar,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1243689256163463169</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>@Eli3nai_ poste, azar é quarentena</td>\n",
       "      <td>poste azar é quarentena</td>\n",
       "      <td>poste azar e quarentena</td>\n",
       "      <td>poste azar e quarentena</td>\n",
       "      <td>[poste, azar, quarentena]</td>\n",
       "      <td>['azar']</td>\n",
       "      <td>[azar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1243689255534239744</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>@ZemaVieira eu indo pro tecno depois da quaren...</td>\n",
       "      <td>eu indo pro tecno depois da quarentena</td>\n",
       "      <td>eu indo pro tecno depois da quarentena</td>\n",
       "      <td>eu indo pro tecno depois da quarentena</td>\n",
       "      <td>[tecno, depois, pro, da, quarentena, eu, indo]</td>\n",
       "      <td>['depois']</td>\n",
       "      <td>[depois]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1243689255471325185</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>quarentena por favor acabe vc está me matando</td>\n",
       "      <td>quarentena por favor acabe vc está me matando</td>\n",
       "      <td>quarentena por favor acabe vc esta me matando</td>\n",
       "      <td>quarentena por favor acabe vc esta me matando</td>\n",
       "      <td>[matando, favor, me, acabe, por, quarentena, v...</td>\n",
       "      <td>['favor', 'me']</td>\n",
       "      <td>[favor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1243689254401826819</td>\n",
       "      <td>2020-03-27 23:59:59</td>\n",
       "      <td>@carlosmaxhado a mãe de todo mundo tá fumando ...</td>\n",
       "      <td>a mãe de todo mundo tá fumando maconha na qua...</td>\n",
       "      <td>a mae de todo mundo ta fumando maconha na qua...</td>\n",
       "      <td>a mae de todo mundo ta fumando maconha na qua...</td>\n",
       "      <td>[na, ta, sonho, mae, todo, fumando, quarentena...</td>\n",
       "      <td>['sonho', 'mae', 'todo', 'mundo', 'maconha']</td>\n",
       "      <td>[sonho, mae, mundo, maconha]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "1  1243689256205406208  2020-03-27 23:59:59   \n",
       "2  1243689256163463169  2020-03-27 23:59:59   \n",
       "3  1243689255534239744  2020-03-27 23:59:59   \n",
       "4  1243689255471325185  2020-03-27 23:59:59   \n",
       "5  1243689254401826819  2020-03-27 23:59:59   \n",
       "\n",
       "                                           full_text  \\\n",
       "1  É bom mostrar na tv mesmo o rosto e depoimento...   \n",
       "2                 @Eli3nai_ poste, azar é quarentena   \n",
       "3  @ZemaVieira eu indo pro tecno depois da quaren...   \n",
       "4      quarentena por favor acabe vc está me matando   \n",
       "5  @carlosmaxhado a mãe de todo mundo tá fumando ...   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "1  é bom mostrar na tv mesmo o rosto e depoimento...   \n",
       "2                            poste azar é quarentena   \n",
       "3             eu indo pro tecno depois da quarentena   \n",
       "4      quarentena por favor acabe vc está me matando   \n",
       "5   a mãe de todo mundo tá fumando maconha na qua...   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "1  e bom mostrar na tv mesmo o rosto e depoimento...   \n",
       "2                            poste azar e quarentena   \n",
       "3             eu indo pro tecno depois da quarentena   \n",
       "4      quarentena por favor acabe vc esta me matando   \n",
       "5   a mae de todo mundo ta fumando maconha na qua...   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "1  e bom mostrar na tv mesmo o rosto e depoimento...   \n",
       "2                            poste azar e quarentena   \n",
       "3             eu indo pro tecno depois da quarentena   \n",
       "4      quarentena por favor acabe vc esta me matando   \n",
       "5   a mae de todo mundo ta fumando maconha na qua...   \n",
       "\n",
       "                                               token  \\\n",
       "1  [imundo, depoimento, mesmo, de, chamar, na, do...   \n",
       "2                          [poste, azar, quarentena]   \n",
       "3     [tecno, depois, pro, da, quarentena, eu, indo]   \n",
       "4  [matando, favor, me, acabe, por, quarentena, v...   \n",
       "5  [na, ta, sonho, mae, todo, fumando, quarentena...   \n",
       "\n",
       "                                              token2  \\\n",
       "1  ['chamar', 'bom', 'imundo', 'depoimento', 'tv'...   \n",
       "2                                           ['azar']   \n",
       "3                                         ['depois']   \n",
       "4                                    ['favor', 'me']   \n",
       "5       ['sonho', 'mae', 'todo', 'mundo', 'maconha']   \n",
       "\n",
       "                                              token3  \n",
       "1  [chamar, bom, imundo, depoimento, tv, mostrar,...  \n",
       "2                                             [azar]  \n",
       "3                                           [depois]  \n",
       "4                                            [favor]  \n",
       "5                       [sonho, mae, mundo, maconha]  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('2703_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 26/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('corona_tweets_26.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1243326867702198275</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>@Juuh_sagawa vc ta fazendo oq o bolsonaro quer😠</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sorocaba, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1243326867664494592</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>até o final dessa quarentena vou assistir goss...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guaraciaba do Norte, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1243326866871681024</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>Nessa quarentena eu tô contribuindo pra fuder ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algarve, Portugal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1243326866750046208</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>11° dia de quarentena ❤🎶 https://t.co/Rw5vfLRvt2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Londrina, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1243326865886138372</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>6º dia de quarentena: já comecei a experimenta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dourados, MS - Brasil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1243326867702198275  2020-03-26 23:59:59   \n",
       "1  1243326867664494592  2020-03-26 23:59:59   \n",
       "2  1243326866871681024  2020-03-26 23:59:59   \n",
       "3  1243326866750046208  2020-03-26 23:59:59   \n",
       "4  1243326865886138372  2020-03-26 23:59:59   \n",
       "\n",
       "                                           full_text country_code lang  \\\n",
       "0    @Juuh_sagawa vc ta fazendo oq o bolsonaro quer😠          NaN   pt   \n",
       "1  até o final dessa quarentena vou assistir goss...          NaN   pt   \n",
       "2  Nessa quarentena eu tô contribuindo pra fuder ...          NaN   pt   \n",
       "3   11° dia de quarentena ❤🎶 https://t.co/Rw5vfLRvt2          NaN   pt   \n",
       "4  6º dia de quarentena: já comecei a experimenta...          NaN   pt   \n",
       "\n",
       "   latitude  longitude                     location  \n",
       "0       NaN        NaN             Sorocaba, Brasil  \n",
       "1       NaN        NaN  Guaraciaba do Norte, Brasil  \n",
       "2       NaN        NaN           Algarve, Portugal.  \n",
       "3       NaN        NaN             Londrina, Brasil  \n",
       "4       NaN        NaN        Dourados, MS - Brasil  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang', 'latitude', 'longitude', 'location'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1243326867702198275</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>@Juuh_sagawa vc ta fazendo oq o bolsonaro quer😠</td>\n",
       "      <td>vc ta fazendo oq o bolsonaro quer😠</td>\n",
       "      <td>vc ta fazendo oq o bolsonaro quer</td>\n",
       "      <td>vc ta fazendo oq o bolsonaro quer</td>\n",
       "      <td>[ta, bolsonaro, oq, quer, fazendo, vc]</td>\n",
       "      <td>['bolsonaro', 'oq']</td>\n",
       "      <td>[bolsonaro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1243326867664494592</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>até o final dessa quarentena vou assistir goss...</td>\n",
       "      <td>até o final dessa quarentena vou assistir goss...</td>\n",
       "      <td>ate o final dessa quarentena vou assistir goss...</td>\n",
       "      <td>ate o final dessa quarentena vou assistir goss...</td>\n",
       "      <td>[gossip, final, assistir, umas, dessa, quarent...</td>\n",
       "      <td>['crtz', 'assistir', 'final']</td>\n",
       "      <td>[crtz, assistir, final]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1243326866871681024</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>Nessa quarentena eu tô contribuindo pra fuder ...</td>\n",
       "      <td>nessa quarentena eu tô contribuindo pra fuder ...</td>\n",
       "      <td>nessa quarentena eu to contribuindo pra fuder ...</td>\n",
       "      <td>nessa quarentena eu to contribuindo pra fuder ...</td>\n",
       "      <td>[to, quero, fuder, pessoas, serem, ver, os, eu...</td>\n",
       "      <td>['fuder', 'ver', 'likes', 'cabelo']</td>\n",
       "      <td>[fuder, likes, cabelo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1243326866750046208</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>11° dia de quarentena ❤🎶 https://t.co/Rw5vfLRvt2</td>\n",
       "      <td>11° dia de quarentena ❤🎶</td>\n",
       "      <td>11 dia de quarentena</td>\n",
       "      <td>11 dia de quarentena</td>\n",
       "      <td>[de, dia, quarentena]</td>\n",
       "      <td>['dia']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1243326865886138372</td>\n",
       "      <td>2020-03-26 23:59:59</td>\n",
       "      <td>6º dia de quarentena: já comecei a experimenta...</td>\n",
       "      <td>6º dia de quarentena já comecei a experimentar...</td>\n",
       "      <td>6o dia de quarentena ja comecei a experimentar...</td>\n",
       "      <td>6o dia de quarentena ja comecei a experimentar...</td>\n",
       "      <td>[6o, comecei, experimentar, receitas, opcoes, ...</td>\n",
       "      <td>['experimentar', 'comida', 'me', 'salsicha', '...</td>\n",
       "      <td>[experimentar, comida, salsicha]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1243326867702198275  2020-03-26 23:59:59   \n",
       "1  1243326867664494592  2020-03-26 23:59:59   \n",
       "2  1243326866871681024  2020-03-26 23:59:59   \n",
       "3  1243326866750046208  2020-03-26 23:59:59   \n",
       "4  1243326865886138372  2020-03-26 23:59:59   \n",
       "\n",
       "                                           full_text  \\\n",
       "0    @Juuh_sagawa vc ta fazendo oq o bolsonaro quer😠   \n",
       "1  até o final dessa quarentena vou assistir goss...   \n",
       "2  Nessa quarentena eu tô contribuindo pra fuder ...   \n",
       "3   11° dia de quarentena ❤🎶 https://t.co/Rw5vfLRvt2   \n",
       "4  6º dia de quarentena: já comecei a experimenta...   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "0                 vc ta fazendo oq o bolsonaro quer😠   \n",
       "1  até o final dessa quarentena vou assistir goss...   \n",
       "2  nessa quarentena eu tô contribuindo pra fuder ...   \n",
       "3                          11° dia de quarentena ❤🎶    \n",
       "4  6º dia de quarentena já comecei a experimentar...   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "0                  vc ta fazendo oq o bolsonaro quer   \n",
       "1  ate o final dessa quarentena vou assistir goss...   \n",
       "2  nessa quarentena eu to contribuindo pra fuder ...   \n",
       "3                             11 dia de quarentena     \n",
       "4  6o dia de quarentena ja comecei a experimentar...   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "0                  vc ta fazendo oq o bolsonaro quer   \n",
       "1  ate o final dessa quarentena vou assistir goss...   \n",
       "2  nessa quarentena eu to contribuindo pra fuder ...   \n",
       "3                             11 dia de quarentena     \n",
       "4  6o dia de quarentena ja comecei a experimentar...   \n",
       "\n",
       "                                               token  \\\n",
       "0             [ta, bolsonaro, oq, quer, fazendo, vc]   \n",
       "1  [gossip, final, assistir, umas, dessa, quarent...   \n",
       "2  [to, quero, fuder, pessoas, serem, ver, os, eu...   \n",
       "3                              [de, dia, quarentena]   \n",
       "4  [6o, comecei, experimentar, receitas, opcoes, ...   \n",
       "\n",
       "                                              token2  \\\n",
       "0                                ['bolsonaro', 'oq']   \n",
       "1                      ['crtz', 'assistir', 'final']   \n",
       "2                ['fuder', 'ver', 'likes', 'cabelo']   \n",
       "3                                            ['dia']   \n",
       "4  ['experimentar', 'comida', 'me', 'salsicha', '...   \n",
       "\n",
       "                             token3  \n",
       "0                       [bolsonaro]  \n",
       "1           [crtz, assistir, final]  \n",
       "2            [fuder, likes, cabelo]  \n",
       "3                                []  \n",
       "4  [experimentar, comida, salsicha]  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('2603_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('corona_tweets_24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1242602092688269312</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>@rfalcao13 O primeiro passo é começar o proces...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Itu - SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1242602092596023298</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>os cara tão criticando o cara que \"escreveu a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1242602092554051584</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>@yassmincarvalh Kkkkkkkk, irmã eu tô até falan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Luís, Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242602092474372096</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>fui ver o pronunciamento e EI BOLSONARO VAI TO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gg stan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1242602092470173699</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>O bolsonaro e toda sua família precisam urgent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z.O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1242602092688269312  2020-03-24 23:59:59   \n",
       "1  1242602092596023298  2020-03-24 23:59:59   \n",
       "2  1242602092554051584  2020-03-24 23:59:59   \n",
       "3  1242602092474372096  2020-03-24 23:59:59   \n",
       "4  1242602092470173699  2020-03-24 23:59:59   \n",
       "\n",
       "                                           full_text country_code lang  \\\n",
       "0  @rfalcao13 O primeiro passo é começar o proces...          NaN   pt   \n",
       "1  os cara tão criticando o cara que \"escreveu a ...          NaN   pt   \n",
       "2  @yassmincarvalh Kkkkkkkk, irmã eu tô até falan...          NaN   pt   \n",
       "3  fui ver o pronunciamento e EI BOLSONARO VAI TO...          NaN   pt   \n",
       "4  O bolsonaro e toda sua família precisam urgent...          NaN   pt   \n",
       "\n",
       "   latitude  longitude          location  \n",
       "0       NaN        NaN          Itu - SP  \n",
       "1       NaN        NaN               NaN  \n",
       "2       NaN        NaN  São Luís, Brasil  \n",
       "3       NaN        NaN           gg stan  \n",
       "4       NaN        NaN               Z.O  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang', 'latitude', 'longitude','location'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1242602092688269312</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>@rfalcao13 O primeiro passo é começar o proces...</td>\n",
       "      <td>o primeiro passo é começar o processo para ti...</td>\n",
       "      <td>o primeiro passo e comecar o processo para ti...</td>\n",
       "      <td>o primeiro passo e comecar o processo para ti...</td>\n",
       "      <td>[mas, processo, apoiam, insano, politicos, emp...</td>\n",
       "      <td>['processo', 'insano', 'politicos', 'empresari...</td>\n",
       "      <td>[processo, insano, politicos, empresarios, pov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1242602092596023298</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>os cara tão criticando o cara que \"escreveu a ...</td>\n",
       "      <td>os cara tão criticando o cara que \"escreveu a ...</td>\n",
       "      <td>os cara tao criticando o cara que \"escreveu a ...</td>\n",
       "      <td>os cara tao criticando o cara que \"escreveu a ...</td>\n",
       "      <td>[cego, escreveu, muito, os, esse, que, verme, ...</td>\n",
       "      <td>['muito', 'tao', 'verme', 'bolsonaro', 'cego']</td>\n",
       "      <td>[muito, verme, bolsonaro, cego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1242602092554051584</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>@yassmincarvalh Kkkkkkkk, irmã eu tô até falan...</td>\n",
       "      <td>kkkkkkkk irmã eu tô até falando coisas p @ qu...</td>\n",
       "      <td>kkkkkkkk irma eu to ate falando coisas p @ qu...</td>\n",
       "      <td>kkkkkkkk irma eu to ate falando coisas p @ qu...</td>\n",
       "      <td>[falando, irma, to, confiando, diria, kkkkkkkk...</td>\n",
       "      <td>['irma', 'so', 'jamais', 'kkkkkkkk']</td>\n",
       "      <td>[irma, jamais]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242602092474372096</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>fui ver o pronunciamento e EI BOLSONARO VAI TO...</td>\n",
       "      <td>fui ver o pronunciamento e ei bolsonaro vai to...</td>\n",
       "      <td>fui ver o pronunciamento e ei bolsonaro vai to...</td>\n",
       "      <td>fui ver o pronunciamento e ei bolsonaro vai to...</td>\n",
       "      <td>[fui, tomar, ver, vai, pronunciamento, bolsona...</td>\n",
       "      <td>['tomar', 'ver', 'pronunciamento', 'bolsonaro'...</td>\n",
       "      <td>[tomar, pronunciamento, bolsonaro, cu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1242602092470173699</td>\n",
       "      <td>2020-03-24 23:59:59</td>\n",
       "      <td>O bolsonaro e toda sua família precisam urgent...</td>\n",
       "      <td>o bolsonaro e toda sua família precisam urgent...</td>\n",
       "      <td>o bolsonaro e toda sua familia precisam urgent...</td>\n",
       "      <td>o bolsonaro e toda sua familia precisam urgent...</td>\n",
       "      <td>[canalhice, um, onde, precisam, sua, senso, va...</td>\n",
       "      <td>['senso', 'pouco', 'ridiculo', 'bolsonaro', 'f...</td>\n",
       "      <td>[senso, pouco, ridiculo, bolsonaro, familia, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1242602092688269312  2020-03-24 23:59:59   \n",
       "1  1242602092596023298  2020-03-24 23:59:59   \n",
       "2  1242602092554051584  2020-03-24 23:59:59   \n",
       "3  1242602092474372096  2020-03-24 23:59:59   \n",
       "4  1242602092470173699  2020-03-24 23:59:59   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  @rfalcao13 O primeiro passo é começar o proces...   \n",
       "1  os cara tão criticando o cara que \"escreveu a ...   \n",
       "2  @yassmincarvalh Kkkkkkkk, irmã eu tô até falan...   \n",
       "3  fui ver o pronunciamento e EI BOLSONARO VAI TO...   \n",
       "4  O bolsonaro e toda sua família precisam urgent...   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "0   o primeiro passo é começar o processo para ti...   \n",
       "1  os cara tão criticando o cara que \"escreveu a ...   \n",
       "2   kkkkkkkk irmã eu tô até falando coisas p @ qu...   \n",
       "3  fui ver o pronunciamento e ei bolsonaro vai to...   \n",
       "4  o bolsonaro e toda sua família precisam urgent...   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "0   o primeiro passo e comecar o processo para ti...   \n",
       "1  os cara tao criticando o cara que \"escreveu a ...   \n",
       "2   kkkkkkkk irma eu to ate falando coisas p @ qu...   \n",
       "3  fui ver o pronunciamento e ei bolsonaro vai to...   \n",
       "4  o bolsonaro e toda sua familia precisam urgent...   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "0   o primeiro passo e comecar o processo para ti...   \n",
       "1  os cara tao criticando o cara que \"escreveu a ...   \n",
       "2   kkkkkkkk irma eu to ate falando coisas p @ qu...   \n",
       "3  fui ver o pronunciamento e ei bolsonaro vai to...   \n",
       "4  o bolsonaro e toda sua familia precisam urgent...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [mas, processo, apoiam, insano, politicos, emp...   \n",
       "1  [cego, escreveu, muito, os, esse, que, verme, ...   \n",
       "2  [falando, irma, to, confiando, diria, kkkkkkkk...   \n",
       "3  [fui, tomar, ver, vai, pronunciamento, bolsona...   \n",
       "4  [canalhice, um, onde, precisam, sua, senso, va...   \n",
       "\n",
       "                                              token2  \\\n",
       "0  ['processo', 'insano', 'politicos', 'empresari...   \n",
       "1     ['muito', 'tao', 'verme', 'bolsonaro', 'cego']   \n",
       "2               ['irma', 'so', 'jamais', 'kkkkkkkk']   \n",
       "3  ['tomar', 'ver', 'pronunciamento', 'bolsonaro'...   \n",
       "4  ['senso', 'pouco', 'ridiculo', 'bolsonaro', 'f...   \n",
       "\n",
       "                                              token3  \n",
       "0  [processo, insano, politicos, empresarios, pov...  \n",
       "1                    [muito, verme, bolsonaro, cego]  \n",
       "2                                     [irma, jamais]  \n",
       "3             [tomar, pronunciamento, bolsonaro, cu]  \n",
       "4  [senso, pouco, ridiculo, bolsonaro, familia, u...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('2403_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('tweets_0319_c_bolsonaro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240790152777281536</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>@Paivamanu_ kkkkkkkkkkkkkkkk aproveitar a quar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240790152613593090</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>@MttzinhuC @uiltoo2 negros de verdade tão com ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240790152462700549</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>@Atanasio_real @l03n27 o loen falando como iss...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240790152458506244</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>a quarentena ta causando sérios problemas ment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240790152454311939</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>Vou passar a quarentena com o meu amô 😩✌🏻😉🥰</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id  created_at  \\\n",
       "0  1240790152777281536  2020-03-19   \n",
       "1  1240790152613593090  2020-03-19   \n",
       "2  1240790152462700549  2020-03-19   \n",
       "3  1240790152458506244  2020-03-19   \n",
       "4  1240790152454311939  2020-03-19   \n",
       "\n",
       "                                                text country_code lang  \n",
       "0  @Paivamanu_ kkkkkkkkkkkkkkkk aproveitar a quar...          NaN   pt  \n",
       "1  @MttzinhuC @uiltoo2 negros de verdade tão com ...          NaN   pt  \n",
       "2  @Atanasio_real @l03n27 o loen falando como iss...          NaN   pt  \n",
       "3  a quarentena ta causando sérios problemas ment...          NaN   pt  \n",
       "4        Vou passar a quarentena com o meu amô 😩✌🏻😉🥰          NaN   pt  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240790152777281536</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>@Paivamanu_ kkkkkkkkkkkkkkkk aproveitar a quar...</td>\n",
       "      <td>kkkkkkkkkkkkkkkk aproveitar a quarentena p re...</td>\n",
       "      <td>kkkkkkkkkkkkkkkk aproveitar a quarentena p re...</td>\n",
       "      <td>kkkkkkkkkkkkkkkk aproveitar a quarentena p re...</td>\n",
       "      <td>[keru, kkkkkkkkkkkkkkkk, num, ficar, naum, apr...</td>\n",
       "      <td>['rezar', 'aproveitar', 'num', 'ficar']</td>\n",
       "      <td>[rezar, aproveitar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240790152613593090</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>@MttzinhuC @uiltoo2 negros de verdade tão com ...</td>\n",
       "      <td>negros de verdade tão com bolsonaro mano\\n\\n...</td>\n",
       "      <td>negros de verdade tao com bolsonaro mano\\n\\n...</td>\n",
       "      <td>negros de verdade tao com bolsonaro mano\\n\\n...</td>\n",
       "      <td>[negros, com, boy, esquerda, bolsonaro, verdad...</td>\n",
       "      <td>['boy', 'bolsonaro', 'verdade', 'branco', 'man...</td>\n",
       "      <td>[boy, bolsonaro, verdade, branco]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240790152462700549</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>@Atanasio_real @l03n27 o loen falando como iss...</td>\n",
       "      <td>o loen falando como isso é coisa de novo-ric...</td>\n",
       "      <td>o loen falando como isso e coisa de novo-ric...</td>\n",
       "      <td>o loen falando como isso e coisa de novo-ric...</td>\n",
       "      <td>[falando, loen, mosca, na, coisa, novo-rico-de...</td>\n",
       "      <td>['coisa', 'corona']</td>\n",
       "      <td>[coisa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240790152458506244</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>a quarentena ta causando sérios problemas ment...</td>\n",
       "      <td>a quarentena ta causando sérios problemas ment...</td>\n",
       "      <td>a quarentena ta causando serios problemas ment...</td>\n",
       "      <td>a quarentena ta causando serios problemas ment...</td>\n",
       "      <td>[aos, ta, causando, problemas, serios, brasile...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240790152454311939</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>Vou passar a quarentena com o meu amô 😩✌🏻😉🥰</td>\n",
       "      <td>vou passar a quarentena com o meu amô 😩✌🏻😉🥰</td>\n",
       "      <td>vou passar a quarentena com o meu amo</td>\n",
       "      <td>vou passar a quarentena com o meu amo</td>\n",
       "      <td>[meu, passar, com, amo, quarentena, vou]</td>\n",
       "      <td>['meu', 'passar', 'amo']</td>\n",
       "      <td>[passar, amo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id  created_at  \\\n",
       "0  1240790152777281536  2020-03-19   \n",
       "1  1240790152613593090  2020-03-19   \n",
       "2  1240790152462700549  2020-03-19   \n",
       "3  1240790152458506244  2020-03-19   \n",
       "4  1240790152454311939  2020-03-19   \n",
       "\n",
       "                                                text  \\\n",
       "0  @Paivamanu_ kkkkkkkkkkkkkkkk aproveitar a quar...   \n",
       "1  @MttzinhuC @uiltoo2 negros de verdade tão com ...   \n",
       "2  @Atanasio_real @l03n27 o loen falando como iss...   \n",
       "3  a quarentena ta causando sérios problemas ment...   \n",
       "4        Vou passar a quarentena com o meu amô 😩✌🏻😉🥰   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "0   kkkkkkkkkkkkkkkk aproveitar a quarentena p re...   \n",
       "1    negros de verdade tão com bolsonaro mano\\n\\n...   \n",
       "2    o loen falando como isso é coisa de novo-ric...   \n",
       "3  a quarentena ta causando sérios problemas ment...   \n",
       "4        vou passar a quarentena com o meu amô 😩✌🏻😉🥰   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "0   kkkkkkkkkkkkkkkk aproveitar a quarentena p re...   \n",
       "1    negros de verdade tao com bolsonaro mano\\n\\n...   \n",
       "2    o loen falando como isso e coisa de novo-ric...   \n",
       "3  a quarentena ta causando serios problemas ment...   \n",
       "4             vou passar a quarentena com o meu amo    \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "0   kkkkkkkkkkkkkkkk aproveitar a quarentena p re...   \n",
       "1    negros de verdade tao com bolsonaro mano\\n\\n...   \n",
       "2    o loen falando como isso e coisa de novo-ric...   \n",
       "3  a quarentena ta causando serios problemas ment...   \n",
       "4             vou passar a quarentena com o meu amo    \n",
       "\n",
       "                                               token  \\\n",
       "0  [keru, kkkkkkkkkkkkkkkk, num, ficar, naum, apr...   \n",
       "1  [negros, com, boy, esquerda, bolsonaro, verdad...   \n",
       "2  [falando, loen, mosca, na, coisa, novo-rico-de...   \n",
       "3  [aos, ta, causando, problemas, serios, brasile...   \n",
       "4           [meu, passar, com, amo, quarentena, vou]   \n",
       "\n",
       "                                              token2  \\\n",
       "0            ['rezar', 'aproveitar', 'num', 'ficar']   \n",
       "1  ['boy', 'bolsonaro', 'verdade', 'branco', 'man...   \n",
       "2                                ['coisa', 'corona']   \n",
       "3                                                 []   \n",
       "4                           ['meu', 'passar', 'amo']   \n",
       "\n",
       "                              token3  \n",
       "0                [rezar, aproveitar]  \n",
       "1  [boy, bolsonaro, verdade, branco]  \n",
       "2                            [coisa]  \n",
       "3                                 []  \n",
       "4                      [passar, amo]  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('1903_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('tweets_0318_c_bolsonaro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240427765431746560</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>Terceiro dia de quarentena e nada mudou. já fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240427765326897152</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>@seonghwanlol This é an manifestação against o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240427765192699907</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>Família, amigos, adoradores, estou bem!! Não e...</td>\n",
       "      <td>BR</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240427765062676481</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>quarentena n é nenhum desafio pra mim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240427764664107009</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>@radaronline O pior é ver o ministro da saúde ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id  created_at  \\\n",
       "0  1240427765431746560  2020-03-18   \n",
       "1  1240427765326897152  2020-03-18   \n",
       "2  1240427765192699907  2020-03-18   \n",
       "3  1240427765062676481  2020-03-18   \n",
       "4  1240427764664107009  2020-03-18   \n",
       "\n",
       "                                                text country_code lang  \n",
       "0  Terceiro dia de quarentena e nada mudou. já fi...          NaN   pt  \n",
       "1  @seonghwanlol This é an manifestação against o...          NaN   pt  \n",
       "2  Família, amigos, adoradores, estou bem!! Não e...           BR   pt  \n",
       "3              quarentena n é nenhum desafio pra mim          NaN   pt  \n",
       "4  @radaronline O pior é ver o ministro da saúde ...          NaN   pt  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240427765431746560</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>Terceiro dia de quarentena e nada mudou. já fi...</td>\n",
       "      <td>terceiro dia de quarentena e nada mudou já fic...</td>\n",
       "      <td>terceiro dia de quarentena e nada mudou ja fic...</td>\n",
       "      <td>terceiro dia de quarentena e nada mudou ja fic...</td>\n",
       "      <td>[mudou, to, terceiro, fico, nada, em, sem, aco...</td>\n",
       "      <td>['terceiro', 'nada', 'todo', 'ja', 'casa', 'dia']</td>\n",
       "      <td>[terceiro, nada, casa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240427765326897152</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>@seonghwanlol This é an manifestação against o...</td>\n",
       "      <td>this é an manifestação against o president bo...</td>\n",
       "      <td>this e an manifestacao against o president bo...</td>\n",
       "      <td>this e an manifestacao against o president bo...</td>\n",
       "      <td>[uma, bolsonaro, day, had, of, this, support, ...</td>\n",
       "      <td>['bolsonaro', 'this']</td>\n",
       "      <td>[bolsonaro, this]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240427765192699907</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>Família, amigos, adoradores, estou bem!! Não e...</td>\n",
       "      <td>família amigos adoradores estou bem!! não esto...</td>\n",
       "      <td>familia amigos adoradores estou bem!! nao esto...</td>\n",
       "      <td>familia amigos adoradores estou bem!! nao esto...</td>\n",
       "      <td>[estou, em, contrai, coronavirus, bem, com, ad...</td>\n",
       "      <td>['coronavirus', 'bem', 'familia', 'casa', 'so'...</td>\n",
       "      <td>[familia, casa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240427765062676481</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>quarentena n é nenhum desafio pra mim</td>\n",
       "      <td>quarentena n é nenhum desafio pra mim</td>\n",
       "      <td>quarentena n e nenhum desafio pra mim</td>\n",
       "      <td>quarentena n e nenhum desafio pra mim</td>\n",
       "      <td>[nenhum, desafio, mim, pra, quarentena]</td>\n",
       "      <td>['nenhum', 'desafio', 'mim']</td>\n",
       "      <td>[nenhum, desafio]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240427764664107009</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>@radaronline O pior é ver o ministro da saúde ...</td>\n",
       "      <td>o pior é ver o ministro da saúde até então ma...</td>\n",
       "      <td>o pior e ver o ministro da saude ate entao ma...</td>\n",
       "      <td>o pior e ver o ministro da saude ate entao ma...</td>\n",
       "      <td>[infantil, saude, ver, da, de, pedido, na, ten...</td>\n",
       "      <td>['infantil', 'entao', 'saude', 'ver', 'compete...</td>\n",
       "      <td>[infantil, saude, competente, coletiva, minist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id  created_at  \\\n",
       "0  1240427765431746560  2020-03-18   \n",
       "1  1240427765326897152  2020-03-18   \n",
       "2  1240427765192699907  2020-03-18   \n",
       "3  1240427765062676481  2020-03-18   \n",
       "4  1240427764664107009  2020-03-18   \n",
       "\n",
       "                                                text  \\\n",
       "0  Terceiro dia de quarentena e nada mudou. já fi...   \n",
       "1  @seonghwanlol This é an manifestação against o...   \n",
       "2  Família, amigos, adoradores, estou bem!! Não e...   \n",
       "3              quarentena n é nenhum desafio pra mim   \n",
       "4  @radaronline O pior é ver o ministro da saúde ...   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "0  terceiro dia de quarentena e nada mudou já fic...   \n",
       "1   this é an manifestação against o president bo...   \n",
       "2  família amigos adoradores estou bem!! não esto...   \n",
       "3              quarentena n é nenhum desafio pra mim   \n",
       "4   o pior é ver o ministro da saúde até então ma...   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "0  terceiro dia de quarentena e nada mudou ja fic...   \n",
       "1   this e an manifestacao against o president bo...   \n",
       "2  familia amigos adoradores estou bem!! nao esto...   \n",
       "3              quarentena n e nenhum desafio pra mim   \n",
       "4   o pior e ver o ministro da saude ate entao ma...   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "0  terceiro dia de quarentena e nada mudou ja fic...   \n",
       "1   this e an manifestacao against o president bo...   \n",
       "2  familia amigos adoradores estou bem!! nao esto...   \n",
       "3              quarentena n e nenhum desafio pra mim   \n",
       "4   o pior e ver o ministro da saude ate entao ma...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [mudou, to, terceiro, fico, nada, em, sem, aco...   \n",
       "1  [uma, bolsonaro, day, had, of, this, support, ...   \n",
       "2  [estou, em, contrai, coronavirus, bem, com, ad...   \n",
       "3            [nenhum, desafio, mim, pra, quarentena]   \n",
       "4  [infantil, saude, ver, da, de, pedido, na, ten...   \n",
       "\n",
       "                                              token2  \\\n",
       "0  ['terceiro', 'nada', 'todo', 'ja', 'casa', 'dia']   \n",
       "1                              ['bolsonaro', 'this']   \n",
       "2  ['coronavirus', 'bem', 'familia', 'casa', 'so'...   \n",
       "3                       ['nenhum', 'desafio', 'mim']   \n",
       "4  ['infantil', 'entao', 'saude', 'ver', 'compete...   \n",
       "\n",
       "                                              token3  \n",
       "0                             [terceiro, nada, casa]  \n",
       "1                                  [bolsonaro, this]  \n",
       "2                                    [familia, casa]  \n",
       "3                                  [nenhum, desafio]  \n",
       "4  [infantil, saude, competente, coletiva, minist...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('1803_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input do dataframe de 01/04\n",
    "\n",
    "df = pd.read_csv('tweets_0317_c_bolsonaro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240065377520037888</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>O problema de estar falando toda hora da doenç...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240065376739889153</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>esse bgl de corona vírus tá chatão já, acaband...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240065376580485120</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>Ou lixão o que vc fez até agora?além de perseg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240065376458887173</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>@carols_lacerda esse corona virus foi longe de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240065376068780033</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>kkkkkk o cara do corre ta com corona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id  created_at  \\\n",
       "0  1240065377520037888  2020-03-17   \n",
       "1  1240065376739889153  2020-03-17   \n",
       "2  1240065376580485120  2020-03-17   \n",
       "3  1240065376458887173  2020-03-17   \n",
       "4  1240065376068780033  2020-03-17   \n",
       "\n",
       "                                                text country_code lang  \n",
       "0  O problema de estar falando toda hora da doenç...          NaN   pt  \n",
       "1  esse bgl de corona vírus tá chatão já, acaband...          NaN   pt  \n",
       "2  Ou lixão o que vc fez até agora?além de perseg...          NaN   pt  \n",
       "3  @carols_lacerda esse corona virus foi longe de...          NaN   pt  \n",
       "4               kkkkkk o cara do corre ta com corona          NaN   pt  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppando colunas irrelevantes\n",
    "\n",
    "df = df.drop(['country_code', 'lang'], axis = 1)\n",
    "\n",
    "# criando listas para incluir os valores\n",
    "letras = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    letras.append(strip_characters(df.iloc[row,2]))\n",
    "    \n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_letras'] = letras\n",
    "\n",
    "# remove acentuação de todos os tokens\n",
    "if __name__ == '__main__':\n",
    "        from doctest import testmod\n",
    "        testmod()\n",
    "\n",
    "# criando listas para incluir os valores        \n",
    "acentos = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    acentos.append(remover_acentos(df.iloc[row,3]))\n",
    "\n",
    "# inclusão dos dados limpos no datafame\n",
    "df['txt_acentos'] = acentos\n",
    "\n",
    "# criando listas para incluir os valores sem emoji\n",
    "token_emoji_free = []\n",
    "\n",
    "# loop para garantir que todas as linhas do dataframe sejam analisadas\n",
    "for row in range(0, len(df)):\n",
    "    token_emoji_free.append(strip_emoji(df.iloc[row,4]))\n",
    "        \n",
    "# inclusão dos dados limpos de emoji no datafame\n",
    "df['txt_emoji_free'] = token_emoji_free\n",
    "\n",
    "# transformando tudo em tokens\n",
    "df['token'] = df['txt_emoji_free'].apply(lambda x: tokenize(x))\n",
    "\n",
    "# filtranso os tokens para aparecer apenas os 10 mil mais frequentes\n",
    "df['token2'] = df.token.apply(lambda x: str(list(set(eval(str(x))).intersection(lista_token))))\n",
    "\n",
    "# transforma os tokens em lista\n",
    "lista = list(df['token2'])\n",
    "\n",
    "# Criando Bigram e Trigram\n",
    "\n",
    "bigram = gensim.models.Phrases(lista, min_count=5, threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[lista], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Processando os tweets\n",
    "texto = process_words(lista)\n",
    "\n",
    "# inserindo no df\n",
    "df['token3'] = texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>txt_letras</th>\n",
       "      <th>txt_acentos</th>\n",
       "      <th>txt_emoji_free</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>token3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240065377520037888</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>O problema de estar falando toda hora da doenç...</td>\n",
       "      <td>o problema de estar falando toda hora da doenç...</td>\n",
       "      <td>o problema de estar falando toda hora da doenc...</td>\n",
       "      <td>o problema de estar falando toda hora da doenc...</td>\n",
       "      <td>[falando, hora, da, ja, de, problema, com, gen...</td>\n",
       "      <td>['ja', 'hora', 'diferente', 'corona', 'gente',...</td>\n",
       "      <td>[hora, diferente, gente, problema]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240065376739889153</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>esse bgl de corona vírus tá chatão já, acaband...</td>\n",
       "      <td>esse bgl de corona vírus tá chatão já acabando...</td>\n",
       "      <td>esse bgl de corona virus ta chatao ja acabando...</td>\n",
       "      <td>esse bgl de corona virus ta chatao ja acabando...</td>\n",
       "      <td>[ja, ta, esse, com, corona, chatao, bgl, meus,...</td>\n",
       "      <td>['ja', 'corona', 'virus']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240065376580485120</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>Ou lixão o que vc fez até agora?além de perseg...</td>\n",
       "      <td>ou lixão o que vc fez até agoraalém de persegu...</td>\n",
       "      <td>ou lixao o que vc fez ate agoraalem de persegu...</td>\n",
       "      <td>ou lixao o que vc fez ate agoraalem de persegu...</td>\n",
       "      <td>[marido, lixo, cambada, ja, de, assim, vao, co...</td>\n",
       "      <td>['vao', 'gordo', 'marido', 'perseguir', 'vagab...</td>\n",
       "      <td>[gordo, marido, perseguir, vagabundo, presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240065376458887173</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>@carols_lacerda esse corona virus foi longe de...</td>\n",
       "      <td>esse corona virus foi longe demais agora</td>\n",
       "      <td>esse corona virus foi longe demais agora</td>\n",
       "      <td>esse corona virus foi longe demais agora</td>\n",
       "      <td>[demais, longe, esse, agora, corona, virus, foi]</td>\n",
       "      <td>['demais', 'longe', 'agora', 'corona', 'virus']</td>\n",
       "      <td>[demais, longe, agora]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240065376068780033</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>kkkkkk o cara do corre ta com corona</td>\n",
       "      <td>kkkkkk o cara do corre ta com corona</td>\n",
       "      <td>kkkkkk o cara do corre ta com corona</td>\n",
       "      <td>kkkkkk o cara do corre ta com corona</td>\n",
       "      <td>[ta, kkkkkk, com, corona, do, cara, corre]</td>\n",
       "      <td>['kkkkkk', 'corona']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id  created_at  \\\n",
       "0  1240065377520037888  2020-03-17   \n",
       "1  1240065376739889153  2020-03-17   \n",
       "2  1240065376580485120  2020-03-17   \n",
       "3  1240065376458887173  2020-03-17   \n",
       "4  1240065376068780033  2020-03-17   \n",
       "\n",
       "                                                text  \\\n",
       "0  O problema de estar falando toda hora da doenç...   \n",
       "1  esse bgl de corona vírus tá chatão já, acaband...   \n",
       "2  Ou lixão o que vc fez até agora?além de perseg...   \n",
       "3  @carols_lacerda esse corona virus foi longe de...   \n",
       "4               kkkkkk o cara do corre ta com corona   \n",
       "\n",
       "                                          txt_letras  \\\n",
       "0  o problema de estar falando toda hora da doenç...   \n",
       "1  esse bgl de corona vírus tá chatão já acabando...   \n",
       "2  ou lixão o que vc fez até agoraalém de persegu...   \n",
       "3           esse corona virus foi longe demais agora   \n",
       "4               kkkkkk o cara do corre ta com corona   \n",
       "\n",
       "                                         txt_acentos  \\\n",
       "0  o problema de estar falando toda hora da doenc...   \n",
       "1  esse bgl de corona virus ta chatao ja acabando...   \n",
       "2  ou lixao o que vc fez ate agoraalem de persegu...   \n",
       "3           esse corona virus foi longe demais agora   \n",
       "4               kkkkkk o cara do corre ta com corona   \n",
       "\n",
       "                                      txt_emoji_free  \\\n",
       "0  o problema de estar falando toda hora da doenc...   \n",
       "1  esse bgl de corona virus ta chatao ja acabando...   \n",
       "2  ou lixao o que vc fez ate agoraalem de persegu...   \n",
       "3           esse corona virus foi longe demais agora   \n",
       "4               kkkkkk o cara do corre ta com corona   \n",
       "\n",
       "                                               token  \\\n",
       "0  [falando, hora, da, ja, de, problema, com, gen...   \n",
       "1  [ja, ta, esse, com, corona, chatao, bgl, meus,...   \n",
       "2  [marido, lixo, cambada, ja, de, assim, vao, co...   \n",
       "3   [demais, longe, esse, agora, corona, virus, foi]   \n",
       "4         [ta, kkkkkk, com, corona, do, cara, corre]   \n",
       "\n",
       "                                              token2  \\\n",
       "0  ['ja', 'hora', 'diferente', 'corona', 'gente',...   \n",
       "1                          ['ja', 'corona', 'virus']   \n",
       "2  ['vao', 'gordo', 'marido', 'perseguir', 'vagab...   \n",
       "3    ['demais', 'longe', 'agora', 'corona', 'virus']   \n",
       "4                               ['kkkkkk', 'corona']   \n",
       "\n",
       "                                              token3  \n",
       "0                 [hora, diferente, gente, problema]  \n",
       "1                                                 []  \n",
       "2  [gordo, marido, perseguir, vagabundo, presiden...  \n",
       "3                             [demais, longe, agora]  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar o DF\n",
    "df.to_csv('1703_preprocessado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
